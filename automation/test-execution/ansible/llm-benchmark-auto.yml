---
# Auto-Configured LLM Test with GuideLLM
# User provides simple core count (e.g., 8, 16, 32) and Ansible auto-configures NUMA/cpuset
# Alternative to run-guidellm-test.yml which requires manual core_config_name
#
# Usage:
#   ansible-playbook playbooks/llm/run-guidellm-test-auto.yml \
#     -i inventory/example-full-config.yml \
#     -e "test_model=meta-llama/Llama-3.2-1B-Instruct" \
#     -e "workload_type=summarization" \
#     -e "requested_cores=16"
#     -e "requested_tensor_parallel=1"  # optional, default=1

- name: "Auto-Configured LLM Test - Setup"
  hosts: localhost
  gather_facts: false
  vars:
    test_run_id: "{{ lookup('pipe', 'date +%Y%m%d-%H%M%S') }}"

  tasks:
    - name: Validate required variables
      ansible.builtin.assert:
        that:
          - test_model is defined
          - workload_type is defined
          - requested_cores is defined
        fail_msg: |
          Missing required variables. Please provide:
          -e "test_model=<model>"
          -e "workload_type=<summarization|chat|code|rag>"
          -e "requested_cores=<8|16|32|64|...>"

    - name: Display auto-config test information
      ansible.builtin.debug:
        msg:
          - "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          - "Auto-Configured LLM Test"
          - "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          - "Test Run ID: {{ test_run_id }}"
          - "Model: {{ test_model }}"
          - "Workload: {{ workload_type }}"
          - "Requested Cores: {{ requested_cores }}"
          - "DUT: {{ groups['dut'][0] }} ({{ hostvars[groups['dut'][0]]['ansible_host'] }})"
          - "Load Generator: {{ groups['load_generator'][0] }} ({{ hostvars[groups['load_generator'][0]]['ansible_host'] }})"
          - "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

    - name: Set vLLM mode
      ansible.builtin.set_fact:
        vllm_mode: "{{ vllm_endpoint.mode | default('managed') }}"

    - name: Set fallback core configuration for external mode
      ansible.builtin.set_fact:
        core_configuration:
          name: "external-endpoint"
          cores: "{{ requested_cores | int }}"
          cpuset_cpus: "n/a"
          cpuset_mems: "n/a"
          tensor_parallel: "{{ requested_tensor_parallel | default(1) | int }}"
      when: vllm_mode == 'external'

    - name: Display vLLM configuration
      ansible.builtin.debug:
        msg:
          - "vLLM Mode: {{ vllm_mode }}"
          - "{{ 'External Endpoint: ' + vllm_endpoint.external.url if vllm_mode == 'external' else 'Managed on DUT: ' + groups['dut'][0] }}"

# ==============================================================================
# STEP 1: Detect NUMA Topology on DUT (Managed Mode Only)
# ==============================================================================

- name: "Auto-Configured LLM Test - Detect NUMA Topology"
  hosts: dut
  become: true

  tasks:
    - block:
        - name: Detect NUMA topology on DUT
          ansible.builtin.include_tasks:
            file: playbooks/common/tasks/detect-numa-topology.yml

      when: hostvars['localhost']['vllm_mode'] == 'managed'
# ==============================================================================
# STEP 2: Allocate Cores from Detected Topology (Managed Mode Only)
# ==============================================================================

- name: "Auto-Configured LLM Test - Allocate Cores"
  hosts: dut
  become: true
  vars:
    requested_cores: "{{ hostvars['localhost']['requested_cores'] }}"
    requested_tensor_parallel: "{{ hostvars['localhost']['requested_tensor_parallel'] | default(1) }}"
    requested_omp_threads: "{{ hostvars['localhost']['requested_omp_threads'] | default(omit) }}"
    requested_omp_bind: "{{ hostvars['localhost']['requested_omp_bind'] | default(omit) }}"

  tasks:
    - block:
        - name: Allocate cores from NUMA topology
          ansible.builtin.include_tasks:
            file: playbooks/common/tasks/allocate-cores-from-count.yml

        - name: Save auto-allocated config to localhost
          ansible.builtin.set_fact:
            core_configuration: "{{ auto_core_config }}"
          delegate_to: localhost
          delegate_facts: true

      when: hostvars['localhost']['vllm_mode'] == 'managed'
# ==============================================================================
# STEP 3: Start vLLM with Auto-Allocated Configuration (Managed Mode Only)
# ==============================================================================
# Note: vllm_server role handles HF token setup and clean restart internally

- name: "Auto-Configured LLM Test - Start vLLM"
  hosts: dut
  become: true
  vars:
    core_configuration: "{{ hostvars['localhost']['core_configuration'] }}"

  pre_tasks:
    - name: Skip if external mode
      ansible.builtin.meta: end_host
      when: hostvars['localhost']['vllm_mode'] != 'managed'

  roles:
    - role: vllm_server
# ==============================================================================
# STEP 3-External: Configure External Endpoint (External Mode Only)
# ==============================================================================

- name: "Step 3-External - Configure External Endpoint"
  hosts: load_generator
  gather_facts: false

  tasks:
    - block:
        - name: Validate external endpoint URL
          ansible.builtin.assert:
            that:
              - vllm_endpoint.external.url is defined
              - vllm_endpoint.external.url is not none
              - vllm_endpoint.external.url | length > 0
            fail_msg: "External endpoint URL is required when mode=external"

        - name: Parse external endpoint URL
          ansible.builtin.set_fact:
            external_endpoint_parsed: "{{ vllm_endpoint.external.url | urlsplit }}"

        - name: Validate parsed endpoint URL
          ansible.builtin.assert:
            that:
              - external_endpoint_parsed.hostname is defined
              - external_endpoint_parsed.hostname is not none
              - external_endpoint_parsed.hostname | length > 0
              - external_endpoint_parsed.scheme is defined
              - external_endpoint_parsed.scheme in ['http', 'https']
            fail_msg: |
              Invalid external endpoint URL: {{ vllm_endpoint.external.url }}
              Parsed hostname: {{ external_endpoint_parsed.hostname | default('MISSING') }}
              Parsed scheme: {{ external_endpoint_parsed.scheme | default('MISSING') }}
              URL must be a valid HTTP/HTTPS URL with a hostname.

        - name: Override bench_config for external endpoint
          ansible.builtin.set_fact:
            bench_config: "{{ bench_config | combine({'vllm_host': external_endpoint_parsed.hostname, 'vllm_port': external_endpoint_parsed.port | default(8000) | int}) }}"

        - name: Setup API key if enabled
          ansible.builtin.include_tasks:
            file: playbooks/common/tasks/setup-vllm-api-key.yml
          when: vllm_endpoint.external.api_key.enabled | default(false) | bool

        - name: Display external endpoint configuration
          ansible.builtin.debug:
            msg:
              - "External vLLM Endpoint: {{ vllm_endpoint.external.url }}"
              - "Parsed Host: {{ bench_config.vllm_host }}"
              - "Parsed Port: {{ bench_config.vllm_port }}"
              - "{{ 'API Key: Enabled' if vllm_api_key is defined else 'API Key: Not configured' }}"

      when: hostvars['localhost']['vllm_mode'] == 'external'
# ==============================================================================
# STEP 4: Health Check
# ==============================================================================

- name: "Auto-Configured LLM Test - Health Check"
  ansible.builtin.import_playbook: health-check.yml

# ==============================================================================
# STEP 5: Run GuideLLM Benchmark
# ==============================================================================

- name: "Auto-Configured LLM Test - Run GuideLLM"
  hosts: load_generator
  become: true
  vars:
    core_configuration: "{{ hostvars['localhost']['core_configuration'] }}"

  roles:
    - role: hf_token
      tasks_from: setup-optional
    - role: benchmark_guidellm

# ==============================================================================
# STEP 6: Collect Results
# ==============================================================================

- name: "Auto-Configured LLM Test - Collect Results"
  hosts: load_generator
  gather_facts: false
  vars:
    test_run_id: "{{ hostvars['localhost']['test_run_id'] }}"
    core_configuration: "{{ hostvars['localhost']['core_configuration'] }}"

  tasks:
    - name: Tag results with auto-config metadata
      ansible.builtin.copy:
        content: |
          {
            "test_run_id": "{{ test_run_id }}",
            "config_type": "auto",
            "core_config_name": "{{ core_configuration.name }}",
            "core_count": {{ core_configuration.cores }},
            "cpuset_cpus": "{{ core_configuration.cpuset_cpus }}",
            "cpuset_mems": "{{ core_configuration.cpuset_mems }}",
            "tensor_parallel": {{ core_configuration.tensor_parallel }},
            "omp_num_threads": {{ core_configuration.omp_num_threads | default('null') }},
            "omp_threads_bind": "{{ core_configuration.omp_threads_bind | default('null') }}",
            "model": "{{ test_model }}",
            "workload": "{{ workload_type }}",
            "timestamp": "{{ ansible_date_time.iso8601 }}"
          }
        dest: "{{ bench_config.results_dir }}/{{ test_model | replace('/', '__') }}/{{ workload_type }}/{{ core_configuration.name }}/test-metadata.json"

    - name: Fetch results to local machine
      ansible.builtin.fetch:
        src: "{{ bench_config.results_dir }}/{{ test_model | replace('/', '__') }}/{{ workload_type }}/{{ core_configuration.name }}/"
        dest: "{{ playbook_dir }}/../../../results/llm/{{ test_model | replace('/', '__') }}/{{ workload_type }}-{{ test_run_id }}/"
        flat: false

    - name: Display results location
      ansible.builtin.debug:
        msg:
          - "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          - "✓ Auto-configured test completed!"
          - "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          - "Configuration: {{ core_configuration.name }}"
          - "  CPUs: {{ core_configuration.cpuset_cpus }}"
          - "  NUMA: {{ core_configuration.cpuset_mems }}"
          - "Results: results/llm/{{ test_model | replace('/', '__') }}/{{ workload_type }}-{{ test_run_id }}/"
          - "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

# ==============================================================================
# STEP 7: Collect Logs (Managed Mode Only)
# ==============================================================================

- name: "Auto-Configured LLM Test - Collect Logs"
  hosts: dut
  become: true
  vars:
    test_run_id: "{{ hostvars['localhost']['test_run_id'] }}"
    core_configuration: "{{ hostvars['localhost']['core_configuration'] }}"

  tasks:
    - block:
        - name: Get vLLM container logs
          ansible.builtin.command:
            cmd: "podman logs {{ vllm_container_name }}"
          register: vllm_logs
          changed_when: false

        - name: Save vLLM logs
          ansible.builtin.copy:
            content: "{{ vllm_logs.stdout }}"
            dest: "{{ log_dir }}/vllm-{{ core_configuration.name }}-{{ test_run_id }}.log"

      when: hostvars['localhost']['vllm_mode'] | default('managed') == 'managed'
# ==============================================================================
# STEP 8: Optional Cleanup (Managed Mode Only)
# ==============================================================================

- name: "Auto-Configured LLM Test - Optional Cleanup"
  hosts: dut
  become: true

  tasks:
    - block:
        - name: Stop and remove vLLM container
          containers.podman.podman_container:
            name: "{{ vllm_container_name }}"
            state: absent

        - name: Display cleanup status
          ansible.builtin.debug:
            msg: "✓ vLLM container stopped and removed"

      when:
        - hostvars['localhost']['vllm_mode'] | default('managed') == 'managed'
        - cleanup_after_test | default(false) | bool
