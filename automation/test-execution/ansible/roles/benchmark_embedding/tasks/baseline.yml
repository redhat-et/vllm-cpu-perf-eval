---
# Baseline performance test tasks (sweep test)
# Included by run-embedding-tests.yml

- name: Set vllm-bench execution mode
  ansible.builtin.set_fact:
    use_vllm_bench_container: "{{ benchmark_tool.vllm_bench.use_container | default(true) }}"
    vllm_bench_image: "{{ benchmark_tool.vllm_bench.container_image | default('quay.io/mtahhan/vllm:arm-base-cpu') }}"
    num_prompts: "{{ benchmark_tool.vllm_bench.num_prompts | default(250) }}"

- name: "Baseline Test - Find Maximum Throughput (inf rate) - Containerized"
  ansible.builtin.command:
    cmd: >
      podman run --rm --entrypoint="" --network host
      -v {{ bench_config.results_dir }}:{{ bench_config.results_dir }}:z
      {{ vllm_bench_image }}
      /opt/venv/bin/vllm bench serve
      --host {{ bench_config.vllm_host }}
      --port {{ bench_config.vllm_port }}
      --backend openai-embeddings
      --model {{ model_name }}
      --dataset-name random
      --random-input-len 512
      --num-prompts {{ num_prompts }}
      --request-rate inf
      --endpoint /v1/embeddings
      --save-result
      --result-filename {{ bench_config.results_dir }}/{{ model_name | basename }}/baseline/sweep-inf.json
  register: baseline_inf_container
  changed_when: true
  when: use_vllm_bench_container | bool

- name: "Baseline Test - Find Maximum Throughput (inf rate) - Host"
  ansible.builtin.command:
    cmd: >
      vllm bench serve
      --host {{ bench_config.vllm_host }}
      --port {{ bench_config.vllm_port }}
      --backend openai-embeddings
      --model {{ model_name }}
      --dataset-name random
      --random-input-len 512
      --num-prompts {{ num_prompts }}
      --request-rate inf
      --endpoint /v1/embeddings
      --save-result
      --result-filename {{ bench_config.results_dir }}/{{ model_name | basename }}/baseline/sweep-inf.json
  register: baseline_inf_host
  changed_when: true
  when: not (use_vllm_bench_container | bool)

- name: Set baseline_inf output
  ansible.builtin.set_fact:
    baseline_inf_output: "{{ (baseline_inf_container.stdout | default('')) if use_vllm_bench_container else (baseline_inf_host.stdout | default('')) }}"

- name: Parse maximum RPS from inf rate test
  ansible.builtin.set_fact:
    max_rps: >-
      {{
        baseline_inf_output
        | regex_search('Request throughput \(req/s\):\s+([0-9.]+)', '\1')
        | first
        | float
      }}

- name: Display maximum RPS
  ansible.builtin.debug:
    msg:
      - "Maximum RPS achieved: {{ max_rps }}"
      - "25% rate: {{ (max_rps * 0.25) | round(2) }}"
      - "50% rate: {{ (max_rps * 0.50) | round(2) }}"
      - "75% rate: {{ (max_rps * 0.75) | round(2) }}"

- name: "Baseline Test - 25% Load - Containerized"
  ansible.builtin.command:
    cmd: >
      podman run --rm --entrypoint="" --network host
      -v {{ bench_config.results_dir }}:{{ bench_config.results_dir }}:z
      {{ vllm_bench_image }}
      /opt/venv/bin/vllm bench serve
      --host {{ bench_config.vllm_host }}
      --port {{ bench_config.vllm_port }}
      --backend openai-embeddings
      --model {{ model_name }}
      --dataset-name random
      --random-input-len 512
      --num-prompts {{ num_prompts }}
      --request-rate {{ (max_rps * 0.25) | round(2) }}
      --endpoint /v1/embeddings
      --save-result
      --result-filename {{ bench_config.results_dir }}/{{ model_name | basename }}/baseline/sweep-25pct.json
  changed_when: true
  when: use_vllm_bench_container | bool

- name: "Baseline Test - 25% Load - Host"
  ansible.builtin.command:
    cmd: >
      vllm bench serve
      --host {{ bench_config.vllm_host }}
      --port {{ bench_config.vllm_port }}
      --backend openai-embeddings
      --model {{ model_name }}
      --dataset-name random
      --random-input-len 512
      --num-prompts {{ num_prompts }}
      --request-rate {{ (max_rps * 0.25) | round(2) }}
      --endpoint /v1/embeddings
      --save-result
      --result-filename {{ bench_config.results_dir }}/{{ model_name | basename }}/baseline/sweep-25pct.json
  changed_when: true
  when: not (use_vllm_bench_container | bool)

- name: "Baseline Test - 50% Load - Containerized"
  ansible.builtin.command:
    cmd: >
      podman run --rm --entrypoint="" --network host
      -v {{ bench_config.results_dir }}:{{ bench_config.results_dir }}:z
      {{ vllm_bench_image }}
      /opt/venv/bin/vllm bench serve
      --host {{ bench_config.vllm_host }}
      --port {{ bench_config.vllm_port }}
      --backend openai-embeddings
      --model {{ model_name }}
      --dataset-name random
      --random-input-len 512
      --num-prompts {{ num_prompts }}
      --request-rate {{ (max_rps * 0.50) | round(2) }}
      --endpoint /v1/embeddings
      --save-result
      --result-filename {{ bench_config.results_dir }}/{{ model_name | basename }}/baseline/sweep-50pct.json
  changed_when: true
  when: use_vllm_bench_container | bool

- name: "Baseline Test - 50% Load - Host"
  ansible.builtin.command:
    cmd: >
      vllm bench serve
      --host {{ bench_config.vllm_host }}
      --port {{ bench_config.vllm_port }}
      --backend openai-embeddings
      --model {{ model_name }}
      --dataset-name random
      --random-input-len 512
      --num-prompts {{ num_prompts }}
      --request-rate {{ (max_rps * 0.50) | round(2) }}
      --endpoint /v1/embeddings
      --save-result
      --result-filename {{ bench_config.results_dir }}/{{ model_name | basename }}/baseline/sweep-50pct.json
  changed_when: true
  when: not (use_vllm_bench_container | bool)

- name: "Baseline Test - 75% Load - Containerized"
  ansible.builtin.command:
    cmd: >
      podman run --rm --entrypoint="" --network host
      -v {{ bench_config.results_dir }}:{{ bench_config.results_dir }}:z
      {{ vllm_bench_image }}
      /opt/venv/bin/vllm bench serve
      --host {{ bench_config.vllm_host }}
      --port {{ bench_config.vllm_port }}
      --backend openai-embeddings
      --model {{ model_name }}
      --dataset-name random
      --random-input-len 512
      --num-prompts {{ num_prompts }}
      --request-rate {{ (max_rps * 0.75) | round(2) }}
      --endpoint /v1/embeddings
      --save-result
      --result-filename {{ bench_config.results_dir }}/{{ model_name | basename }}/baseline/sweep-75pct.json
  changed_when: true
  when: use_vllm_bench_container | bool

- name: "Baseline Test - 75% Load - Host"
  ansible.builtin.command:
    cmd: >
      vllm bench serve
      --host {{ bench_config.vllm_host }}
      --port {{ bench_config.vllm_port }}
      --backend openai-embeddings
      --model {{ model_name }}
      --dataset-name random
      --random-input-len 512
      --num-prompts {{ num_prompts }}
      --request-rate {{ (max_rps * 0.75) | round(2) }}
      --endpoint /v1/embeddings
      --save-result
      --result-filename {{ bench_config.results_dir }}/{{ model_name | basename }}/baseline/sweep-75pct.json
  changed_when: true
  when: not (use_vllm_bench_container | bool)

- name: Display baseline test completion
  ansible.builtin.debug:
    msg: "Baseline sweep tests completed. Results saved to {{ bench_config.results_dir }}/{{ model_name | basename }}/baseline/"
