---
# Start vLLM for LLM Generative Models
# Supports tensor parallelism, custom workloads, optional OMP configuration

- name: Setup HuggingFace token
  ansible.builtin.include_role:
    name: hf_token
    tasks_from: setup-optional

- name: Clean restart vLLM container
  ansible.builtin.include_tasks:
    file: clean-restart.yml

- name: Create required directories
  ansible.builtin.file:
    path: "{{ item.path }}"
    state: directory
    mode: "{{ item.mode }}"
  loop:
    - {path: "{{ model_cache_dir }}", mode: "0777"}  # Container needs write access
    - {path: "{{ log_dir }}", mode: "0777"}
  when: use_persistent_cache | default(false) | bool

- name: Get workload and core configuration
  ansible.builtin.set_fact:
    workload_cfg: "{{ test_configs[workload_type] }}"
    core_cfg: "{{ core_configuration }}"
    container_cfg: "{{ container_runtime }}"

- name: Validate workload type
  ansible.builtin.assert:
    that:
      - workload_type in ['summarization', 'chat', 'code', 'rag']
    fail_msg: "Invalid workload_type: {{ workload_type }}. Must be one of: summarization, chat, code, rag"

# ============================================================================
# CPU Configuration Validation
# ============================================================================

- name: Get available CPU count on target system
  ansible.builtin.command: nproc --all
  register: available_cpus_result
  changed_when: false

- name: Parse CPU configuration
  ansible.builtin.set_fact:
    available_cpus: "{{ available_cpus_result.stdout | int }}"
    max_cpu_id: "{{ (available_cpus_result.stdout | int) - 1 }}"

- name: Validate cpuset_cpus format
  ansible.builtin.assert:
    that:
      - core_cfg.cpuset_cpus is match('^[0-9,-]+$')
    fail_msg: |
      ❌ Invalid cpuset_cpus format: {{ core_cfg.cpuset_cpus }}

      Format must contain only digits, hyphens, and commas.
      Valid examples:
        - Single CPU: "7"
        - Range: "0-15"
        - Comma-separated: "0-3,8-11"
        - Mixed: "0,4-7,12"
    success_msg: "✓ CPU format validated: {{ core_cfg.cpuset_cpus }}"

- name: Split cpuset_cpus into segments
  ansible.builtin.set_fact:
    cpu_segments: "{{ core_cfg.cpuset_cpus.split(',') }}"

- name: Validate each CPU segment
  ansible.builtin.assert:
    that:
      # For single CPU: validate it's a number within range
      - >-
        (item is match('^\\d+$') and item | int >= 0 and item | int <= max_cpu_id | int)
        or
        # For range: validate both start and end are numbers within range
        (item is match('^\\d+-\\d+$') and
         item.split('-')[0] | int >= 0 and
         item.split('-')[0] | int <= max_cpu_id | int and
         item.split('-')[1] | int >= 0 and
         item.split('-')[1] | int <= max_cpu_id | int and
         item.split('-')[0] | int <= item.split('-')[1] | int)
    fail_msg: |
      ❌ CPU configuration error in segment "{{ item }}"!

      Configured cpuset_cpus: {{ core_cfg.cpuset_cpus }}
      Available CPUs on {{ inventory_hostname }}: 0-{{ max_cpu_id }} ({{ available_cpus }} total)

      Invalid segment: {{ item }}
      {% if item is match('^\\d+-\\d+$') %}
      {% if item.split('-')[0] | int > item.split('-')[1] | int %}
      Error: Range start ({{ item.split('-')[0] }}) is greater than range end ({{ item.split('-')[1] }})
      {% else %}
      Error: Range {{ item }} is out of bounds (valid: 0-{{ max_cpu_id }})
      {% endif %}
      {% elif item is match('^\\d+$') %}
      Error: CPU ID {{ item }} is out of bounds (valid: 0-{{ max_cpu_id }})
      {% else %}
      Error: Invalid format "{{ item }}" (expected single CPU or range like "0-15")
      {% endif %}

      Please update inventory/group_vars/all/hardware-profiles.yml to match your hardware.
    success_msg: "✓ CPU segment validated: {{ item }}"
  loop: "{{ cpu_segments }}"

- name: Set CPU validation status
  ansible.builtin.set_fact:
    cpu_cfg_valid: true

- name: Display CPU allocation summary
  ansible.builtin.debug:
    msg:
      - "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
      - "CPU Validation Summary"
      - "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
      - "Target System: {{ inventory_hostname }}"
      - "Available CPUs: {{ available_cpus }} (0-{{ max_cpu_id }})"
      - "Configured Allocation: {{ core_cfg.cpuset_cpus }}"
      - "NUMA Node: {{ core_cfg.cpuset_mems }}"
      - "Status: {{ '✓ Valid configuration' if cpu_cfg_valid else '✗ Invalid configuration' }}"
      - "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

# ============================================================================
# End CPU Configuration Validation
# ============================================================================

- name: Prepare base environment variables
  ansible.builtin.set_fact:
    vllm_env_vars:
      VLLM_CPU_KVCACHE_SPACE: "{{ workload_cfg.kv_cache_space | extract_size_value }}"
      HF_TOKEN: "{{ hf_token }}"

- name: Add OMP_NUM_THREADS if specified (OPTIONAL)
  ansible.builtin.set_fact:
    vllm_env_vars: "{{ vllm_env_vars | combine({'OMP_NUM_THREADS': core_cfg.omp_num_threads | string}) }}"
  when:
    - core_cfg.omp_num_threads is defined
    - core_cfg.omp_num_threads is not none

- name: Add VLLM_CPU_OMP_THREADS_BIND if specified (OPTIONAL)
  ansible.builtin.set_fact:
    vllm_env_vars: "{{ vllm_env_vars | combine({'VLLM_CPU_OMP_THREADS_BIND': core_cfg.omp_threads_bind}) }}"
  when:
    - core_cfg.omp_threads_bind is defined
    - core_cfg.omp_threads_bind is not none

- name: Build vLLM command arguments
  ansible.builtin.set_fact:
    vllm_cmd: >-
      --model {{ test_model }}
      --host {{ vllm_server.host }}
      --port {{ vllm_server.port }}
      {{ workload_cfg.vllm_args | join(' ') }}
      {% if core_cfg.tensor_parallel > 1 %}-tp {{ core_cfg.tensor_parallel }}{% endif %}

- name: Pull vLLM container image
  containers.podman.podman_container:
    name: "{{ vllm_container_name }}"
    image: "{{ container_cfg.image }}"
    state: present
  when: container_cfg.engine == 'podman'

- name: Display vLLM configuration
  ansible.builtin.debug:
    msg:
      - "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
      - "Starting vLLM for LLM Generative Model"
      - "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
      - "Model: {{ test_model }}"
      - "Workload: {{ workload_type }} (ISL:{{ workload_cfg.isl }}/OSL:{{ workload_cfg.osl }})"
      - "Image: {{ container_cfg.image }}"
      - "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
      - "Container CPU Allocation:"
      - "  CPUs: {{ core_cfg.cpuset_cpus }}"
      - "  NUMA: {{ core_cfg.cpuset_mems }}"
      - "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
      - "vLLM Configuration:"
      - "  Tensor Parallel: {{ core_cfg.tensor_parallel }}"
      - "  KV Cache: {{ workload_cfg.kv_cache_space }} (VLLM_CPU_KVCACHE_SPACE={{ workload_cfg.kv_cache_space | extract_size_value }})"
      - "  OMP Threads: {{ core_cfg.omp_num_threads | default('auto') }}"
      - "  OMP Bind: {{ core_cfg.omp_threads_bind | default('auto') }}"
      - "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

- name: Start vLLM LLM server
  containers.podman.podman_container:
    name: "{{ vllm_container_name }}"
    image: "{{ container_cfg.image }}"
    state: started
    restart_policy: "no"
    detach: true
    rm: "{{ container_cfg.remove_on_stop | default(true) }}"
    network: "{{ container_cfg.network_mode }}"
    shm_size: "{{ container_cfg.shm_size | default('4g') }}"
    security_opt: "{{ container_cfg.security_opts | default([]) }}"
    cap_add: "{{ container_cfg.capabilities | default([]) }}"
    cpuset_cpus: "{{ core_cfg.cpuset_cpus }}"
    cpuset_mems: "{{ core_cfg.cpuset_mems }}"
    volumes: "{{ [model_cache_dir + ':/root/.cache/huggingface:rw', log_dir + ':/var/log/vllm:rw'] if (use_persistent_cache | default(false) | bool) else [] }}"
    env: "{{ vllm_env_vars }}"
    command: "{{ vllm_cmd }}"
    log_driver: journald
    log_opt:
      tag: "vllm-{{ workload_type }}-{{ core_cfg.cores }}c-tp{{ core_cfg.tensor_parallel }}"
  when: container_cfg.engine == 'podman'
  register: vllm_container

- name: Display vLLM container info
  ansible.builtin.debug:
    msg:
      - "✓ vLLM LLM Container Started"
      - "Container ID: {{ vllm_container.container.Id[:12] if vllm_container.container is defined else 'N/A' }}"
      - "Server: http://{{ ansible_host }}:{{ vllm_server.port }}"
      - "Logs: journalctl -t vllm-{{ workload_type }}-{{ core_cfg.cores }}c-tp{{ core_cfg.tensor_parallel }} -f"
      - "Stats: podman stats {{ vllm_container_name }}"

- name: Wait for vLLM initialization (longer for LLM models)
  ansible.builtin.pause:
    seconds: 20
    prompt: "Waiting for vLLM to download model and initialize (this may take a while for large models)..."
