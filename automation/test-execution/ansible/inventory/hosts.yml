---
# ============================================================================
# vLLM Performance Testing - Main Inventory File
# ============================================================================
#
# QUICK START:
# 1. Update the two IP addresses:
#    - Line 41: vLLM server (DUT) IP
#    - Line 50: Load generator IP (same or different machine)
#    Note: vllm_host (where GuideLLM connects) auto-references the DUT IP
# 2. Update ansible_user and ansible_ssh_private_key_file if different
# 3. Set HF_TOKEN environment variable (if using gated models): export HF_TOKEN=hf_xxxxx
# 4. Run tests!
#
# Configuration files are now organized in group_vars/ directory:
#   - group_vars/all/infrastructure.yml  - Platform and container settings
#   - group_vars/all/endpoints.yml       - vLLM server and endpoint mode
#   - group_vars/all/benchmark-tools.yml - GuideLLM and vllm_bench config
#   - group_vars/all/credentials.yml     - HuggingFace token setup
#   - group_vars/all/test-workloads.yml  - Test configurations
#   - group_vars/all/hardware-profiles.yml - CPU/NUMA templates
#
# See inventory/README.md for detailed documentation
# ============================================================================

# ============================================================================
# HOST CONFIGURATION - ⚠️ CHANGE THESE VALUES ⚠️
# ============================================================================

all:
  vars:
    # Common connection settings (override per-host if needed)
    ansible_user: ec2-user
    ansible_ssh_private_key_file: ~/mtahhan.pem

  children:
    # DUT (Device Under Test) - Runs vLLM server
    dut:
      hosts:
        vllm-server:
          # ⚠️ CHANGE: Your vLLM server IP or hostname
          ansible_host: ec2-XX-XXX-XX-XXX.us-east-2.compute.amazonaws.com

    # Load Generator - Runs GuideLLM benchmarking tool
    load_generator:
      hosts:
        guidellm-client:
          # ⚠️ CHANGE: Your load generator IP or hostname
          # For separate machines: Use different IP from DUT
          # For same machine: Use same IP as DUT
          ansible_host: ec2-YY-YYY-YY-YYY.us-east-2.compute.amazonaws.com

      vars:
        # Benchmark configuration
        bench_config:
          # Automatically uses the DUT's ansible_host
          # Override here if you need different IPs (e.g., private IP for benchmarking)
          vllm_host: "{{ hostvars['vllm-server']['ansible_host'] }}"
          vllm_port: 8000

          # Results storage location on load generator
          results_dir: "{{ lookup('env', 'HOME') }}/benchmark-results"

# ============================================================================
# COMMON DEPLOYMENT SCENARIOS
# ============================================================================
#
# 1. SEPARATE MACHINES (Default - No changes needed):
#    - Set DUT ansible_host (line 41)
#    - Set Load Gen ansible_host (line 50)
#    - vllm_host automatically references DUT IP
#
# 2. SAME MACHINE (Override vllm_host for localhost):
#    - Set both ansible_host to same IP
#    - Override vllm_host in bench_config:
#      bench_config:
#        vllm_host: localhost  # Faster than external IP
#
# 3. PRIVATE IP OPTIMIZATION (Same VPC):
#    - SSH via public IPs (ansible_host)
#    - Override vllm_host to use private IP for benchmarking:
#      bench_config:
#        vllm_host: 10.0.1.100  # DUT's private IP (faster in VPC)
#
# ============================================================================

# ============================================================================
# USAGE EXAMPLES
# ============================================================================
#
# 1. Test Ansible connectivity:
#    ansible -i inventory/hosts.yml all -m ping
#
# 2. Run platform setup (one-time, requires reboot):
#    ansible-playbook -i inventory/hosts.yml setup-platform.yml
#    ansible -i inventory/hosts.yml all -b -m reboot
#
# 3. Run LLM benchmark:
#    export HF_TOKEN=hf_xxxxx  # If using gated models
#    ansible-playbook -i inventory/hosts.yml \
#      llm-benchmark.yml \
#      -e "test_model=Qwen/Qwen2.5-3B-Instruct" \
#      -e "workload_type=chat" \
#      -e "core_config_name=16cores-single-socket"
#
# ============================================================================
