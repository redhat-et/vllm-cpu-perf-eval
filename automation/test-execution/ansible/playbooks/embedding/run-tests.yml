---
# Main playbook for running embedding model performance tests
# Two-node architecture: Start vLLM on DUT, wait for ready, then run tests from Load Generator

- name: "Embedding Performance Tests - Complete Workflow"
  hosts: localhost
  gather_facts: false
  vars:
    test_run_id: "{{ lookup('pipe', 'date +%Y%m%d-%H%M%S') }}"

  tasks:
    - name: Display test run information
      ansible.builtin.debug:
        msg:
          - "Test Run ID: {{ test_run_id }}"
          - "DUT Host: {{ groups['dut'][0] }}"
          - "Load Generator Host: {{ groups['load_generator'][0] }}"

# ==============================================================================
# PHASE 1: Prepare and Start vLLM Server on DUT
# ==============================================================================

- name: "Phase 1 - Start vLLM Server on DUT"
  hosts: dut
  become: true
  vars:
    model_name: "{{ test_model | default('ibm-granite/granite-embedding-278m-multilingual') }}"

  tasks:
    - name: Create log directory on DUT
      ansible.builtin.file:
        path: "{{ log_dir }}"
        state: directory
        mode: "0755"

    - name: Create model cache directory
      ansible.builtin.file:
        path: "{{ model_cache_dir }}"
        state: directory
        mode: "0755"

    - name: Pull vLLM container image
      containers.podman.podman_image:
        name: "{{ vllm_server.container_image }}"
        state: present
      when: vllm_server.container_runtime == 'podman'

    - name: Stop any existing vLLM container
      containers.podman.podman_container:
        name: vllm-embedding-server
        state: absent
      ignore_errors: true
      when: vllm_server.container_runtime == 'podman'

    - name: Start vLLM server in container
      containers.podman.podman_container:
        name: vllm-embedding-server
        image: "{{ vllm_server.container_image }}"
        state: started
        restart_policy: "no"
        detach: true
        network: host
        volumes:
          - "{{ model_cache_dir }}:/root/.cache/huggingface:rw"
          - "{{ log_dir }}:/var/log/vllm:rw"
        env: "{{ vllm_env }}"
        command: >
          --model {{ model_name }}
          --host {{ vllm_server.host }}
          --port {{ vllm_server.port }}
          --dtype bfloat16
          --max-model-len 512
        log_driver: journald
        log_opt:
          tag: vllm-embedding
      when: vllm_server.container_runtime == 'podman'
      register: vllm_container

    - name: Display vLLM container start info
      ansible.builtin.debug:
        msg:
          - "vLLM Container ID: {{ vllm_container.container.Id | default('N/A') }}"
          - "vLLM Server: http://{{ ansible_host }}:{{ vllm_server.port }}"
          - "Model: {{ model_name }}"
          - "Check logs: journalctl -t vllm-embedding -f"

    - name: Wait a few seconds for container to initialize
      ansible.builtin.pause:
        seconds: 10

# ==============================================================================
# PHASE 2: Health Check - Wait for vLLM to be Ready
# ==============================================================================

- name: "Phase 2 - Wait for vLLM Server to be Ready"
  hosts: load_generator
  gather_facts: false

  tasks:
    - name: Wait for vLLM health endpoint
      ansible.builtin.uri:
        url: "http://{{ bench_config.vllm_host }}:{{ bench_config.vllm_port }}/health"
        method: GET
        status_code: 200
      register: health_check
      retries: "{{ health_check.timeout // health_check.interval }}"
      delay: "{{ health_check.interval }}"
      until: health_check.status == 200

    - name: Display vLLM server status
      ansible.builtin.debug:
        msg:
          - "vLLM Server is READY!"
          - "Health check: {{ health_check.json | default('OK') }}"

    - name: Verify vLLM /v1/models endpoint
      ansible.builtin.uri:
        url: "http://{{ bench_config.vllm_host }}:{{ bench_config.vllm_port }}/v1/models"
        method: GET
        status_code: 200
      register: models_check

    - name: Display available models
      ansible.builtin.debug:
        msg: "Available models: {{ models_check.json.data | map(attribute='id') | list }}"

# ==============================================================================
# PHASE 3: Run Embedding Tests from Load Generator
# ==============================================================================

- name: "Phase 3 - Run Embedding Performance Tests"
  hosts: load_generator
  become: true
  vars:
    model_name: "{{ test_model | default('ibm-granite/granite-embedding-278m-multilingual') }}"
    test_scenario: "{{ scenario | default('baseline') }}"  # baseline or latency

  tasks:
    - name: Create results directory on load generator
      ansible.builtin.file:
        path: "{{ bench_config.results_dir }}/{{ model_name | basename }}/{{ test_scenario }}"
        state: directory
        mode: "0755"
        recurse: true

    - name: Include test scenario tasks
      ansible.builtin.include_tasks:
        file: "tasks/{{ test_scenario }}.yml"

# ==============================================================================
# PHASE 4: Collect Logs and Results
# ==============================================================================

- name: "Phase 4 - Collect Logs and Results"
  hosts: load_generator
  gather_facts: false

  tasks:
    - name: Fetch results from load generator to controller
      ansible.builtin.fetch:
        src: "{{ bench_config.results_dir }}/"
        dest: "{{ playbook_dir }}/../../results/embedding-models/"
        flat: false

- name: "Phase 4 - Collect vLLM Server Logs"
  hosts: dut
  become: true

  tasks:
    - name: Get vLLM container logs
      ansible.builtin.command:
        cmd: "podman logs vllm-embedding-server"
      register: vllm_logs
      when: vllm_server.container_runtime == 'podman'

    - name: Save vLLM logs to file
      ansible.builtin.copy:
        content: "{{ vllm_logs.stdout }}"
        dest: "{{ log_dir }}/vllm-server-{{ test_run_id }}.log"
      when: vllm_logs is defined

    - name: Fetch vLLM logs to controller
      ansible.builtin.fetch:
        src: "{{ log_dir }}/vllm-server-{{ test_run_id }}.log"
        dest: "{{ playbook_dir }}/../../results/logs/"
        flat: false

# ==============================================================================
# PHASE 5: Cleanup (Optional)
# ==============================================================================

- name: "Phase 5 - Cleanup (if requested)"
  hosts: dut
  become: true
  vars:
    cleanup: "{{ cleanup_after_test | default(false) }}"

  tasks:
    - name: Stop vLLM container
      containers.podman.podman_container:
        name: vllm-embedding-server
        state: stopped
      when:
        - cleanup | bool
        - vllm_server.container_runtime == 'podman'

    - name: Display cleanup status
      ansible.builtin.debug:
        msg: "vLLM server {{ 'stopped' if cleanup else 'still running - use cleanup_after_test=true to stop' }}"
