---
# Single Auto Core Configuration Iteration
# Allocates cores from NUMA topology and runs one test

# ==============================================================================
# STEP 1: Allocate Cores from NUMA Topology
# ==============================================================================

- name: "Allocate {{ current_cores }} cores from NUMA topology"
  hosts: dut
  become: true
  vars:
    requested_cores: "{{ hostvars['localhost']['current_cores'] }}"
    requested_tensor_parallel: "{{ hostvars['localhost']['requested_tensor_parallel'] | default(1) }}"
    requested_omp_threads: "{{ hostvars['localhost']['requested_omp_threads'] | default(omit) }}"
    requested_omp_bind: "{{ hostvars['localhost']['requested_omp_bind'] | default(omit) }}"
    numa_topology: "{{ hostvars['localhost']['dut_numa_topology'] }}"

  tasks:
    - name: Allocate cores from NUMA topology
      ansible.builtin.include_tasks:
        file: ../../common/tasks/allocate-cores-from-count.yml

    - name: Save auto-allocated config to localhost
      ansible.builtin.set_fact:
        current_core_config: "{{ auto_core_config }}"
      delegate_to: localhost
      delegate_facts: true

# ==============================================================================
# STEP 2: Clean Restart vLLM
# ==============================================================================

- name: "Clean restart vLLM for {{ hostvars['localhost']['current_cores'] }} cores"
  hosts: dut
  become: true

  tasks:
    - name: Clean restart vLLM
      ansible.builtin.include_tasks:
        file: ../../common/tasks/clean-restart-vllm.yml

# ==============================================================================
# STEP 3: Start vLLM with Auto-Allocated Configuration
# ==============================================================================

- name: "Start vLLM with {{ hostvars['localhost']['current_cores'] }} cores"
  hosts: dut
  become: true
  vars:
    core_configuration: "{{ hostvars['localhost']['current_core_config'] }}"

  tasks:
    - name: Display iteration info
      ansible.builtin.debug:
        msg:
          - "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          - "Auto Config: {{ core_configuration.name }}"
          - "Cores: {{ core_configuration.cores }} ({{ core_configuration.cpuset_cpus }})"
          - "NUMA: {{ core_configuration.cpuset_mems }}"
          - "Tensor Parallel: {{ core_configuration.tensor_parallel }}"
          - "OMP Threads: {{ core_configuration.omp_num_threads | default('auto') }}"
          - "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

    - name: Start vLLM for LLM model
      ansible.builtin.include_tasks:
        file: start-llm-vllm.yml

# ==============================================================================
# STEP 4: Health Check
# ==============================================================================

- name: "Health check for {{ hostvars['localhost']['current_cores'] }} cores"
  hosts: load_generator
  gather_facts: false

  tasks:
    - name: Wait for vLLM health endpoint
      ansible.builtin.uri:
        url: "http://{{ bench_config.vllm_host }}:{{ bench_config.vllm_port }}/health"
        method: GET
        status_code: 200
      register: health_check_result
      retries: 60
      delay: 5
      until: health_check_result.status == 200

    - name: Display readiness status
      ansible.builtin.debug:
        msg: "✓ vLLM is ready with {{ hostvars['localhost']['current_core_config'].name }}"

# ==============================================================================
# STEP 5: Run GuideLLM Benchmark
# ==============================================================================

- name: "Run GuideLLM with {{ hostvars['localhost']['current_cores'] }} cores"
  hosts: load_generator
  become: true
  vars:
    core_configuration: "{{ hostvars['localhost']['current_core_config'] }}"

  tasks:
    - name: Setup HuggingFace token for load generator
      ansible.builtin.include_tasks:
        file: ../../common/tasks/setup-hf-token-optional.yml

    - name: Run GuideLLM benchmark
      ansible.builtin.include_tasks:
        file: run-guidellm.yml

    - name: Tag results with auto-config metadata
      ansible.builtin.copy:
        content: |
          {
            "test_run_id": "{{ hostvars['localhost']['test_run_id'] }}",
            "config_type": "auto",
            "core_config_name": "{{ core_configuration.name }}",
            "core_count": {{ core_configuration.cores }},
            "cpuset_cpus": "{{ core_configuration.cpuset_cpus }}",
            "cpuset_mems": "{{ core_configuration.cpuset_mems }}",
            "tensor_parallel": {{ core_configuration.tensor_parallel }},
            "omp_num_threads": {{ core_configuration.omp_num_threads | default('null') }},
            "omp_threads_bind": "{{ core_configuration.omp_threads_bind | default('null') }}",
            "model": "{{ test_model }}",
            "workload": "{{ workload_type }}",
            "timestamp": "{{ ansible_date_time.iso8601 }}"
          }
        dest: "{{ bench_config.results_dir }}/{{ test_model | basename }}/{{ workload_type }}/{{ core_configuration.name }}/test-metadata.json"

# ==============================================================================
# STEP 6: Collect Logs
# ==============================================================================

- name: "Collect logs for {{ hostvars['localhost']['current_cores'] }} cores"
  hosts: dut
  become: true
  vars:
    core_configuration: "{{ hostvars['localhost']['current_core_config'] }}"

  tasks:
    - name: Get vLLM container logs
      ansible.builtin.command:
        cmd: "podman logs {{ vllm_container_name }}"
      register: vllm_logs
      changed_when: false

    - name: Save vLLM logs
      ansible.builtin.copy:
        content: "{{ vllm_logs.stdout }}"
        dest: "{{ log_dir }}/vllm-{{ core_configuration.name }}-{{ hostvars['localhost']['test_run_id'] }}.log"

# ==============================================================================
# STEP 7: Stop vLLM Container (Clean for Next Iteration)
# ==============================================================================

- name: "Stop vLLM container ({{ hostvars['localhost']['current_cores'] }} cores)"
  hosts: dut
  become: true

  tasks:
    - name: Stop and remove vLLM container
      containers.podman.podman_container:
        name: "{{ vllm_container_name }}"
        state: absent

    - name: Display cleanup status
      ansible.builtin.debug:
        msg: "✓ vLLM container stopped for {{ hostvars['localhost']['current_core_config'].name }}"

    - name: Wait before next iteration
      ansible.builtin.pause:
        seconds: 10
      when: hostvars['localhost']['current_cores'] != hostvars['localhost']['requested_cores_list'][-1]
